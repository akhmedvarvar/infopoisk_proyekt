{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "dataset = load_dataset(\"Pablinho/movies-dataset\")\n",
    "data = dataset['train'].to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['en', 'ja', 'fr', 'hi', 'es', 'ru', 'de', 'th', 'ko', 'tr', 'cn',\n",
       "       'zh', 'it', 'pt', 'ml', 'pl', 'fi', 'no', 'da', 'id', 'sv', None,\n",
       "       'https://image.tmdb.org/t/p/original/6iXYe7AkQ1QIfMFuvXsSCT2zF7s.jpg',\n",
       "       'nl', 'te', 'sr', 'is', 'ro', 'tl', 'fa', 'uk', 'nb', 'eu', 'lv',\n",
       "       'ar', 'el', 'cs', 'ms', 'bn', 'ca', 'la', 'ta', 'hu', 'he', 'et'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.Original_Language.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "model = TfidfVectorizer(max_features=5000, stop_words=\"english\")\n",
    "\n",
    "tfidf_matrix = model.fit_transform(data['Overview'].fillna(''))\n",
    "\n",
    "#save vectorizer\n",
    "import pickle\n",
    "with open('tfidf_vectorizer.pkl', 'wb') as f:\n",
    "    pickle.dump(model, f)\n",
    "\n",
    "# load vectorizer\n",
    "with open('tfidf_vectorizer.pkl', 'rb') as f:\n",
    "    model = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpairwise\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m cosine_similarity\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtfidf_vectorizer\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TfidfVectorizerModel\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'sklearn'"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "from models.tfidf_vectorizer import TfidfVectorizerModel\n",
    "from models.embedding_model import EmbeddingModel\n",
    "from utils.text_preprocessing import preprocess_text\n",
    "\n",
    "class SearchEngine:\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "        self.tfidf_model = TfidfVectorizerModel()\n",
    "        self.embedding_model = EmbeddingModel()\n",
    "        \n",
    "        # Prepare data\n",
    "        self.data['processed_overview'] = self.data['Overview'].fillna('').apply(preprocess_text)\n",
    "        self.tfidf_matrix = self.tfidf_model.fit_transform(self.data['processed_overview'])\n",
    "        self.embeddings = self.embedding_model.encode(self.data['processed_overview'].tolist())\n",
    "\n",
    "    def search(self, query, method='tfidf', top_n=10):\n",
    "        query = preprocess_text(query)\n",
    "        \n",
    "        if method == 'tfidf':\n",
    "            query_vector = self.tfidf_model.transform([query])\n",
    "            scores = cosine_similarity(query_vector, self.tfidf_matrix).flatten()\n",
    "        elif method == 'embedding':\n",
    "            query_vector = self.embedding_model.encode([query])\n",
    "            scores = cosine_similarity(query_vector, self.embeddings).flatten()\n",
    "        else:\n",
    "            raise ValueError(\"Invalid method. Choose 'tfidf' or 'embedding'.\")\n",
    "\n",
    "        top_indices = np.argsort(scores)[::-1][:top_n]\n",
    "        results = self.data.iloc[top_indices]\n",
    "        \n",
    "        return results[['Title', 'Overview', 'Popularity', 'Vote_Average']], scores[top_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF matrix shape: (3, 9)\n",
      "<Compressed Sparse Row sparse matrix of dtype 'float64'\n",
      "\twith 9 stored elements and shape (3, 9)>\n",
      "  Coords\tValues\n",
      "  (0, 6)\t0.5773502691896257\n",
      "  (0, 0)\t0.5773502691896257\n",
      "  (0, 1)\t0.5773502691896257\n",
      "  (1, 5)\t0.5773502691896257\n",
      "  (1, 7)\t0.5773502691896257\n",
      "  (1, 4)\t0.5773502691896257\n",
      "  (2, 8)\t0.5773502691896257\n",
      "  (2, 2)\t0.5773502691896257\n",
      "  (2, 3)\t0.5773502691896257\n",
      "Query vector shape: (1, 9)\n",
      "<Compressed Sparse Row sparse matrix of dtype 'float64'\n",
      "\twith 1 stored elements and shape (1, 9)>\n",
      "  Coords\tValues\n",
      "  (0, 0)\t1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "class TfidfVectorizerModel:\n",
    "    def __init__(self, max_features=5000, stop_words='english'):\n",
    "        \"\"\"\n",
    "        Initializes the TF-IDF Vectorizer Model.\n",
    "\n",
    "        Args:\n",
    "            max_features (int): Maximum number of features for the TF-IDF vectorizer.\n",
    "            stop_words (str): Stop words to use during vectorization.\n",
    "        \"\"\"\n",
    "        self.vectorizer = TfidfVectorizer(max_features=max_features, stop_words=stop_words)\n",
    "\n",
    "    def fit_transform(self, corpus):\n",
    "        \"\"\"\n",
    "        Fits the TF-IDF vectorizer to the corpus and transforms it.\n",
    "\n",
    "        Args:\n",
    "            corpus (list[str]): List of preprocessed text documents.\n",
    "\n",
    "        Returns:\n",
    "            sparse matrix: Transformed TF-IDF matrix.\n",
    "        \"\"\"\n",
    "        return self.vectorizer.fit_transform(corpus)\n",
    "\n",
    "    def transform(self, query):\n",
    "        \"\"\"\n",
    "        Transforms a query using the fitted TF-IDF vectorizer.\n",
    "\n",
    "        Args:\n",
    "            query (list[str]): List containing the query text.\n",
    "\n",
    "        Returns:\n",
    "            sparse matrix: Transformed query vector.\n",
    "        \"\"\"\n",
    "        return self.vectorizer.transform(query)\n",
    "\n",
    "corpus = [\n",
    "    \"Space adventure with aliens\",\n",
    "    \"A romantic story in Paris\",\n",
    "    \"A thriller with a detective in London\"\n",
    "]\n",
    "\n",
    "model = TfidfVectorizerModel()\n",
    "tfidf_matrix = model.fit_transform(corpus)\n",
    "query_vector = model.transform([\"alien adventure\"])\n",
    "\n",
    "print(\"TF-IDF matrix shape:\", tfidf_matrix.shape)\n",
    "print(tfidf_matrix)\n",
    "print(\"Query vector shape:\", query_vector.shape)\n",
    "print(query_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The cache for model files in Transformers v4.22.0 has been updated. Migrating your old cache. This is a one-time only operation. You can interrupt this and resume the migration later on by calling `transformers.utils.move_cache()`.\n",
      "0it [00:00, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings shape: (3, 384)\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "class EmbeddingModel:\n",
    "    def __init__(self, model_name='all-MiniLM-L6-v2'):\n",
    "        \"\"\"\n",
    "        Initializes the Embedding Model using SentenceTransformers.\n",
    "\n",
    "        Args:\n",
    "            model_name (str): Name of the pre-trained model to use for embeddings.\n",
    "        \"\"\"\n",
    "        self.model = SentenceTransformer(model_name)\n",
    "\n",
    "    def encode(self, texts):\n",
    "        \"\"\"\n",
    "        Encodes a list of texts into embeddings.\n",
    "\n",
    "        Args:\n",
    "            texts (list[str]): List of preprocessed text documents.\n",
    "\n",
    "        Returns:\n",
    "            np.ndarray: Array of embeddings for the input texts.\n",
    "        \"\"\"\n",
    "        return self.model.encode(texts, convert_to_numpy=True)\n",
    "\n",
    "\n",
    "texts = [\n",
    "    \"Space adventure with aliens\",\n",
    "    \"A romantic story in Paris\",\n",
    "    \"A thriller with a detective in London\"\n",
    "]\n",
    "\n",
    "embedding_model = EmbeddingModel()\n",
    "embeddings = embedding_model.encode(texts)\n",
    "\n",
    "print(\"Embeddings shape:\", embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Compressed Sparse Row sparse matrix of dtype 'float64'\n",
       "\twith 3 stored elements and shape (1, 9)>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_matrix[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jointist",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
